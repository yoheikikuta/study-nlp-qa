{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is constructed from https://github.com/Kyubyong/transformer for my study.\n",
    "\n",
    "Dataset is http://www.phontron.com/kftt/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"./corpora-jp-en\"):\n",
    "    os.makedirs(\"./corpora-jp-en\", exist_ok=True)\n",
    "    !wget -qO- --show-progress http://www.phontron.com/kftt/download/kftt-data-1.0.tar.gz | tar xz; mv kftt-data-1.0 corpora-jp-en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hyperparams:\n",
    "    '''Hyperparameters'''\n",
    "    # data\n",
    "    source_train = './corpora-jp-en/kftt-data-1.0/data/tok/kyoto-train.ja'\n",
    "    target_train = './corpora-jp-en/kftt-data-1.0/data/tok/kyoto-train.en'\n",
    "    source_test = './corpora-jp-en/kftt-data-1.0/data/tok/kyoto-test.ja'\n",
    "    target_test = './corpora-jp-en/kftt-data-1.0/data/tok/kyoto-test.en'\n",
    "    \n",
    "    # training\n",
    "    batch_size = 32 # alias = N\n",
    "    lr = 0.0001 # learning rate. In paper, learning rate is adjusted to the global step.\n",
    "    logdir = 'logdir-jp-en' # log directory\n",
    "    \n",
    "    # model\n",
    "    maxlen = 10 # Maximum number of words in a sentence. alias = T.  Feel free to increase this if you are ambitious.\n",
    "    min_cnt = 20 # words whose occurred less than min_cnt are encoded as <UNK>.\n",
    "    hidden_units = 512 # alias = C\n",
    "    num_blocks = 6 # number of encoder/decoder blocks\n",
    "    num_epochs = 20\n",
    "    num_heads = 8\n",
    "    dropout_rate = 0.1\n",
    "    sinusoid = False # If True, use sinusoid. If false, positional embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = Hyperparams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions for data handling and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import codecs\n",
    "import os\n",
    "import regex\n",
    "from collections import Counter\n",
    "\n",
    "def make_vocab(fpath\n",
    "               , fname\n",
    "              , is_ja = False):\n",
    "    '''Constructs vocabulary.\n",
    "    \n",
    "    Args:\n",
    "      fpath: A string. Input file path.\n",
    "      fname: A string. Output file name.\n",
    "    \n",
    "    Writes vocabulary line by line to `preprocessed/fname`\n",
    "    '''  \n",
    "    text = codecs.open(fpath, 'r', 'utf-8').read()\n",
    "    if is_ja == False:\n",
    "        text = regex.sub(\"[^\\s\\p{Latin}']\", \"\", text)\n",
    "    words = text.split()\n",
    "    word2cnt = Counter(words)\n",
    "    \n",
    "    if not os.path.exists('preprocessed-jp-en'): os.mkdir('preprocessed-jp-en')\n",
    "    \n",
    "    with codecs.open('preprocessed-jp-en/{}'.format(fname), 'w', 'utf-8') as fout:\n",
    "        fout.write(\"{}\\t1000000000\\n{}\\t1000000000\\n{}\\t1000000000\\n{}\\t1000000000\\n\".format(\"<PAD>\", \"<UNK>\", \"<S>\", \"</S>\"))\n",
    "        for word, cnt in word2cnt.most_common(len(word2cnt)):\n",
    "            fout.write(u\"{}\\t{}\\n\".format(word, cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists.\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 1.42 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if not os.path.exists(\"./preprocessed-jp-en/ja.vocab.tsv\"):\n",
    "    make_vocab(hp.source_train, \"ja.vocab.tsv\", is_ja=True)\n",
    "    make_vocab(hp.target_train, \"en.vocab.tsv\")\n",
    "    print(\"Done\")\n",
    "else:\n",
    "    print(\"File already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(inputs\n",
    "              , epsilon = 1e-8\n",
    "              , scope=\"ln\"\n",
    "              , reuse=None):\n",
    "    '''Applies layer normalization.\n",
    "    \n",
    "    Args:\n",
    "      inputs: A tensor with 2 or more dimensions, where the first dimension has `batch_size`.\n",
    "      epsilon: A floating number. A very small number for preventing ZeroDivision Error.\n",
    "      scope: Optional scope for `variable_scope`.\n",
    "      reuse: Boolean, whether to reuse the weights of a previous layer by the same name.\n",
    "      \n",
    "    Returns:\n",
    "      A tensor with the same shape and data dtype as `inputs`.\n",
    "    '''\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "        inputs_shape = inputs.get_shape()\n",
    "        params_shape = inputs_shape[-1:]\n",
    "    \n",
    "        mean, variance = tf.nn.moments(inputs, [-1], keep_dims=True)\n",
    "        beta= tf.Variable(tf.zeros(params_shape)) #Is this necessary?\n",
    "        gamma = tf.Variable(tf.ones(params_shape))\n",
    "        normalized = (inputs - mean) / ( (variance + epsilon) ** (.5) )\n",
    "        outputs = gamma * normalized + beta\n",
    "        \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.2247448   0.          1.2247448 ]\n",
      " [-1.0690448  -0.26726115  1.3363062 ]]\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.constant([[1.0, 2.0, 3.0],[4.0, 8.0, 16.0]], name=\"test\")\n",
    "outputs = normalize(inputs, scope='test')\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding(inputs\n",
    "              , vocab_size\n",
    "              , num_units\n",
    "              , zero_pad=True\n",
    "              , scale=True\n",
    "              , scope=\"embedding\"\n",
    "              , reuse=None):\n",
    "    '''Embeds a given tensor.\n",
    "    Args:\n",
    "      inputs: A `Tensor` with type `int32` or `int64` containing the ids to be looked up in `lookup table`.\n",
    "      vocab_size: An int. Vocabulary size.\n",
    "      num_units: An int. Number of embedding hidden units.\n",
    "      zero_pad: A boolean. If True, all the values of the fist row (id 0) should be constant zeros.\n",
    "      scale: A boolean. If True. the outputs is multiplied by sqrt num_units.\n",
    "      scope: Optional scope for `variable_scope`.\n",
    "      reuse: Boolean, whether to reuse the weights of a previous layer by the same name.\n",
    "    Returns:\n",
    "      A `Tensor` with one more rank than inputs's. The last dimensionality should be `num_units`.\n",
    "        \n",
    "    For example,\n",
    "    \n",
    "    ```\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    inputs = tf.to_int32(tf.reshape(tf.range(2*3), (2, 3)))\n",
    "    outputs = embedding(inputs, 6, 2, zero_pad=True)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print sess.run(outputs)\n",
    "    >>\n",
    "    [[[ 0.          0.        ]\n",
    "      [ 0.09754146  0.67385566]\n",
    "      [ 0.37864095 -0.35689294]]\n",
    "     [[-1.01329422 -1.09939694]\n",
    "      [ 0.7521342   0.38203377]\n",
    "      [-0.04973143 -0.06210355]]]\n",
    "    ```\n",
    "    \n",
    "    ```\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    inputs = tf.to_int32(tf.reshape(tf.range(2*3), (2, 3)))\n",
    "    outputs = embedding(inputs, 6, 2, zero_pad=False)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print sess.run(outputs)\n",
    "    >>\n",
    "    [[[-0.19172323 -0.39159766]\n",
    "      [-0.43212751 -0.66207761]\n",
    "      [ 1.03452027 -0.26704335]]\n",
    "     [[-0.11634696 -0.35983452]\n",
    "      [ 0.50208133  0.53509563]\n",
    "      [ 1.22204471 -0.96587461]]]    \n",
    "    ```    \n",
    "    '''\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "        lookup_table = tf.get_variable('lookup_table'\n",
    "                                       , dtype=tf.float32\n",
    "                                       , shape=[vocab_size, num_units]\n",
    "                                       , initializer=tf.contrib.layers.xavier_initializer())\n",
    "        if zero_pad:\n",
    "            lookup_table = tf.concat((tf.zeros(shape=[1, num_units]), lookup_table[1:, :]), 0)\n",
    "        outputs = tf.nn.embedding_lookup(lookup_table, inputs)\n",
    "        \n",
    "        if scale:\n",
    "            outputs = outputs * (num_units ** 0.5) \n",
    "            \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.68886787  0.70741284]\n",
      "  [-0.13518551  0.9180102 ]\n",
      "  [-1.0187594   0.36321706]]\n",
      "\n",
      " [[-0.5569595  -1.1951034 ]\n",
      "  [-0.50075996  1.1593267 ]\n",
      "  [ 0.78773326 -0.8533228 ]]]\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.to_int32(tf.reshape(tf.range(2*3), (2, 3)))\n",
    "outputs = embedding(inputs, 6, 2, zero_pad=False)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print( sess.run(outputs) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape:0' shape=(2, 3) dtype=int32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Tensor.get_shape of <tf.Tensor 'embedding/mul:0' shape=(2, 3, 2) dtype=float32>>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.get_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last dimension 2 is for num_units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(inputs\n",
    "                        , num_units\n",
    "                        , zero_pad=True\n",
    "                        , scale=True\n",
    "                        , scope=\"positional_encoding\"\n",
    "                        , reuse=None):\n",
    "    '''Sinusoidal Positional_Encoding.\n",
    "    Args:\n",
    "      inputs: A 2d Tensor with shape of (N, T).\n",
    "      num_units: Output dimensionality\n",
    "      zero_pad: Boolean. If True, all the values of the first row (id = 0) should be constant zero\n",
    "      scale: Boolean. If True, the output will be multiplied by sqrt num_units(check details from paper)\n",
    "      scope: Optional scope for `variable_scope`.\n",
    "      reuse: Boolean, whether to reuse the weights of a previous layer by the same name.\n",
    "    Returns:\n",
    "        A 'Tensor' with one more rank than inputs's, with the dimensionality should be 'num_units'\n",
    "    '''\n",
    "\n",
    "    N, T = inputs.get_shape().as_list()\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "        position_ind = tf.tile(tf.expand_dims(tf.range(T), 0), [N, 1])\n",
    "\n",
    "        # First part of the PE function: sin and cos argument\n",
    "        position_enc = np.array([ [pos / np.power(10000, 2.*i/num_units) for i in range(num_units)] for pos in range(T) ])\n",
    "\n",
    "        # Second part, apply the cosine to even columns and sin to odds.\n",
    "        position_enc[:, 0::2] = np.sin(position_enc[:, 0::2])  # dim 2i\n",
    "        position_enc[:, 1::2] = np.cos(position_enc[:, 1::2])  # dim 2i+1\n",
    "\n",
    "        # Convert to a tensor\n",
    "        lookup_table = tf.convert_to_tensor(position_enc)\n",
    "\n",
    "        if zero_pad:\n",
    "            lookup_table = tf.concat((tf.zeros(shape=[1, num_units]), lookup_table[1:, :]), 0)\n",
    "        outputs = tf.nn.embedding_lookup(lookup_table, position_ind)\n",
    "\n",
    "        if scale:\n",
    "            outputs = outputs * num_units**0.5\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.         1.41421356]\n",
      "  [1.19001968 1.41421356]\n",
      "  [1.28594075 1.41421353]\n",
      "  [0.19957383 1.4142135 ]]\n",
      "\n",
      " [[0.         1.41421356]\n",
      "  [1.19001968 1.41421356]\n",
      "  [1.28594075 1.41421353]\n",
      "  [0.19957383 1.4142135 ]]\n",
      "\n",
      " [[0.         1.41421356]\n",
      "  [1.19001968 1.41421356]\n",
      "  [1.28594075 1.41421353]\n",
      "  [0.19957383 1.4142135 ]]]\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.constant([[0, 0, 0, 0],[0, 1, 0, 0],[0, 0, 1, 0]])\n",
    "outputs = positional_encoding(inputs, 2, zero_pad=False)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print( sess.run(outputs) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Tensor.get_shape of <tf.Tensor 'Const:0' shape=(3, 4) dtype=int32>>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.get_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.e+00, 0.e+00, 0.e+00, 0.e+00],\n",
       "       [1.e+00, 1.e-02, 1.e-04, 1.e-06],\n",
       "       [2.e+00, 2.e-02, 2.e-04, 2.e-06]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([ [pos / np.power(10000, 2.*i/4) for i in range(4)] for pos in range(3) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multihead_attention(queries, \n",
    "                        keys, \n",
    "                        num_units=None, \n",
    "                        num_heads=8, \n",
    "                        dropout_rate=0,\n",
    "                        is_training=True,\n",
    "                        causality=False,\n",
    "                        scope=\"multihead_attention\", \n",
    "                        reuse=None):\n",
    "    '''Applies multihead attention.\n",
    "    \n",
    "    Args:\n",
    "      queries: A 3d tensor with shape of [N, T_q, C_q].\n",
    "      keys: A 3d tensor with shape of [N, T_k, C_k].\n",
    "      num_units: A scalar. Attention size.\n",
    "      dropout_rate: A floating point number.\n",
    "      is_training: Boolean. Controller of mechanism for dropout.\n",
    "      causality: Boolean. If true, units that reference the future are masked. \n",
    "      num_heads: An int. Number of heads.\n",
    "      scope: Optional scope for `variable_scope`.\n",
    "      reuse: Boolean, whether to reuse the weights of a previous layer by the same name.\n",
    "        \n",
    "    Returns\n",
    "      A 3d tensor with shape of (N, T_q, C)  \n",
    "    '''\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "        # Set the fall back option for num_units\n",
    "        if num_units is None:\n",
    "            num_units = queries.get_shape().as_list[-1]\n",
    "        \n",
    "        # Linear projections\n",
    "        Q = tf.layers.dense(queries, num_units, activation=tf.nn.relu) # (N, T_q, C)\n",
    "        K = tf.layers.dense(keys, num_units, activation=tf.nn.relu) # (N, T_k, C)\n",
    "        V = tf.layers.dense(keys, num_units, activation=tf.nn.relu) # (N, T_k, C)\n",
    "        \n",
    "        # Split and concat\n",
    "        Q_ = tf.concat(tf.split(Q, num_heads, axis=2), axis=0) # (h*N, T_q, C/h) \n",
    "        K_ = tf.concat(tf.split(K, num_heads, axis=2), axis=0) # (h*N, T_k, C/h) \n",
    "        V_ = tf.concat(tf.split(V, num_heads, axis=2), axis=0) # (h*N, T_k, C/h) \n",
    "\n",
    "        # Multiplication\n",
    "        outputs = tf.matmul(Q_, tf.transpose(K_, [0, 2, 1])) # (h*N, T_q, T_k) < Q_ * K_^T\n",
    "        \n",
    "        # Scale\n",
    "        outputs = outputs / (K_.get_shape().as_list()[-1] ** 0.5)\n",
    "        \n",
    "        # Key Masking\n",
    "        key_masks = tf.sign(tf.abs(tf.reduce_sum(keys, axis=-1))) # (N, T_k) < get sign < compute abs < sum over hidden units\n",
    "        key_masks = tf.tile(key_masks, [num_heads, 1]) # (h*N, T_k)\n",
    "        key_masks = tf.tile(tf.expand_dims(key_masks, 1), [1, tf.shape(queries)[1], 1]) # (h*N, T_q, T_k)\n",
    "        \n",
    "        paddings = tf.ones_like(outputs)*(-2**32+1)\n",
    "        outputs = tf.where(tf.equal(key_masks, 0), paddings, outputs) # (h*N, T_q, T_k)\n",
    "  \n",
    "        # Causality = Future blinding\n",
    "        if causality:\n",
    "            diag_vals = tf.ones_like(outputs[0, :, :]) # (T_q, T_k)\n",
    "            tril = tf.contrib.linalg.LinearOperatorTriL(diag_vals).to_dense() # (T_q, T_k) < LinearOperator acting like a [batch] square lower triangular matrix\n",
    "            masks = tf.tile(tf.expand_dims(tril, 0), [tf.shape(outputs)[0], 1, 1]) # (h*N, T_q, T_k)\n",
    "   \n",
    "            paddings = tf.ones_like(masks)*(-2**32+1)\n",
    "            outputs = tf.where(tf.equal(masks, 0), paddings, outputs) # (h*N, T_q, T_k)\n",
    "  \n",
    "        # Activation\n",
    "        outputs = tf.nn.softmax(outputs) # (h*N, T_q, T_k)\n",
    "         \n",
    "        # Query Masking\n",
    "        query_masks = tf.sign(tf.abs(tf.reduce_sum(queries, axis=-1))) # (N, T_q)\n",
    "        query_masks = tf.tile(query_masks, [num_heads, 1]) # (h*N, T_q)\n",
    "        query_masks = tf.tile(tf.expand_dims(query_masks, -1), [1, 1, tf.shape(keys)[1]]) # (h*N, T_q, T_k)\n",
    "        outputs *= query_masks # broadcasting. (N, T_q, C)\n",
    "          \n",
    "        # Dropouts\n",
    "        outputs = tf.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(is_training))\n",
    "               \n",
    "        # Weighted sum\n",
    "        outputs = tf.matmul(outputs, V_) # ( h*N, T_q, C/h) < masked(Q_ * K_^T) * V_\n",
    "        \n",
    "        # Restore shape\n",
    "        outputs = tf.concat( tf.split(outputs, num_heads, axis=0), axis=2 ) # (N, T_q, C)\n",
    "              \n",
    "        # Residual connection\n",
    "        outputs += queries\n",
    "              \n",
    "        # Normalize\n",
    "        outputs = normalize(outputs) # (N, T_q, C)\n",
    " \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward(inputs\n",
    "                , num_units=[2048, 512] #Two hidden layers\n",
    "                , scope=\"multihead_attention\"\n",
    "                , reuse=None):\n",
    "    '''Point-wise feed forward net.\n",
    "    \n",
    "    Args:\n",
    "      inputs: A 3d tensor with shape of [N, T, C].\n",
    "      num_units: A list of two integers.\n",
    "      scope: Optional scope for `variable_scope`.\n",
    "      reuse: Boolean, whether to reuse the weights of a previous layer by the same name.\n",
    "        \n",
    "    Returns:\n",
    "      A 3d tensor with the same shape and dtype as inputs\n",
    "    '''\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "        # Inner layer\n",
    "        params = {\"inputs\": inputs, \"filters\": num_units[0], \"kernel_size\": 1,\n",
    "                  \"activation\": tf.nn.relu, \"use_bias\": True}\n",
    "        outputs = tf.layers.conv1d(**params)\n",
    "        \n",
    "        # Readout layer\n",
    "        params = {\"inputs\": outputs, \"filters\": num_units[1], \"kernel_size\": 1,\n",
    "                  \"activation\": None, \"use_bias\": True}\n",
    "        outputs = tf.layers.conv1d(**params)\n",
    "        \n",
    "        # Residual connection\n",
    "        outputs += inputs\n",
    "        \n",
    "        # Normalize\n",
    "        outputs = normalize(outputs)\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_smoothing(inputs\n",
    "                    , epsilon=0.1):\n",
    "    '''Applies label smoothing. See https://arxiv.org/abs/1512.00567.\n",
    "    \n",
    "    Args:\n",
    "      inputs: A 3d tensor with shape of [N, T, V], where V is the number of vocabulary.\n",
    "      epsilon: Smoothing rate.\n",
    "    \n",
    "    For example,\n",
    "    \n",
    "    ```\n",
    "    import tensorflow as tf\n",
    "    inputs = tf.convert_to_tensor([[[0, 0, 1], \n",
    "       [0, 1, 0],\n",
    "       [1, 0, 0]],\n",
    "      [[1, 0, 0],\n",
    "       [1, 0, 0],\n",
    "       [0, 1, 0]]], tf.float32)\n",
    "       \n",
    "    outputs = label_smoothing(inputs)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        print(sess.run([outputs]))\n",
    "    \n",
    "    >>\n",
    "    [array([[[ 0.03333334,  0.03333334,  0.93333334],\n",
    "        [ 0.03333334,  0.93333334,  0.03333334],\n",
    "        [ 0.93333334,  0.03333334,  0.03333334]],\n",
    "       [[ 0.93333334,  0.03333334,  0.03333334],\n",
    "        [ 0.93333334,  0.03333334,  0.03333334],\n",
    "        [ 0.03333334,  0.93333334,  0.03333334]]], dtype=float32)]   \n",
    "    ```    \n",
    "    '''\n",
    "    K = inputs.get_shape().as_list()[-1] # number of channels\n",
    "    return ((1-epsilon) * inputs) + (epsilon / K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ja_vocab():\n",
    "    vocab = [line.split()[0] for line in codecs.open('preprocessed-jp-en/ja.vocab.tsv', 'r', 'utf-8').read().splitlines() if int(line.split()[1])>=hp.min_cnt]\n",
    "    word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "    idx2word = {idx: word for idx, word in enumerate(vocab)}\n",
    "    return word2idx, idx2word\n",
    "\n",
    "def load_en_vocab():\n",
    "    vocab = [line.split()[0] for line in codecs.open('preprocessed-jp-en/en.vocab.tsv', 'r', 'utf-8').read().splitlines() if int(line.split()[1])>=hp.min_cnt]\n",
    "    word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "    idx2word = {idx: word for idx, word in enumerate(vocab)}\n",
    "    return word2idx, idx2word\n",
    "\n",
    "def create_data(source_sents, target_sents): \n",
    "    ja2idx, idx2ja = load_ja_vocab()\n",
    "    en2idx, idx2en = load_en_vocab()\n",
    "    \n",
    "    # Index\n",
    "    x_list, y_list, Sources, Targets = [], [], [], []\n",
    "    for source_sent, target_sent in zip(source_sents, target_sents):\n",
    "        x = [ja2idx.get(word, 1) for word in (source_sent + u\" </S>\").split()] # 1: OOV, </S>: End of Text\n",
    "        y = [en2idx.get(word, 1) for word in (target_sent + u\" </S>\").split()] \n",
    "        if max(len(x), len(y)) <=hp.maxlen:\n",
    "            x_list.append(np.array(x))\n",
    "            y_list.append(np.array(y))\n",
    "            Sources.append(source_sent)\n",
    "            Targets.append(target_sent)\n",
    "    \n",
    "    # Pad      \n",
    "    X = np.zeros([len(x_list), hp.maxlen], np.int32)\n",
    "    Y = np.zeros([len(y_list), hp.maxlen], np.int32)\n",
    "    for i, (x, y) in enumerate(zip(x_list, y_list)):\n",
    "        X[i] = np.lib.pad(x, [0, hp.maxlen-len(x)], 'constant', constant_values=(0, 0))\n",
    "        Y[i] = np.lib.pad(y, [0, hp.maxlen-len(y)], 'constant', constant_values=(0, 0))\n",
    "    \n",
    "    return X, Y, Sources, Targets\n",
    "\n",
    "def load_train_data():\n",
    "    ja_sents = [line for line in codecs.open(hp.source_train, 'r', 'utf-8').read().split(\"\\n\") if line and line[0] != \"<\"]\n",
    "    en_sents = [regex.sub(\"[^\\s\\p{Latin}']\", \"\", line) for line in codecs.open(hp.target_train, 'r', 'utf-8').read().split(\"\\n\") if line and line[0] != \"<\"]\n",
    "    \n",
    "    X, Y, Sources, Targets = create_data(ja_sents, en_sents)\n",
    "    return X, Y\n",
    "    \n",
    "def load_test_data():\n",
    "    ja_sents = [line for line in codecs.open(hp.source_test, 'r', 'utf-8').read().split(\"\\n\") if line and line[0] != \"<\"]\n",
    "    en_sents = [regex.sub(\"[^\\s\\p{Latin}']\", \"\", line) for line in codecs.open(hp.target_test, 'r', 'utf-8').read().split(\"\\n\") if line and line[0] != \"<\"]\n",
    "        \n",
    "    X, Y, Sources, Targets = create_data(ja_sents, en_sents)\n",
    "    return X, Sources, Targets\n",
    "\n",
    "def get_batch_data():\n",
    "    # Load data\n",
    "    X, Y = load_train_data()\n",
    "    \n",
    "    # calc total batch count\n",
    "    num_batch = len(X) // hp.batch_size\n",
    "    \n",
    "    # Convert to tensor\n",
    "    X = tf.convert_to_tensor(X, tf.int32)\n",
    "    Y = tf.convert_to_tensor(Y, tf.int32)\n",
    "    \n",
    "    # Create Queues\n",
    "    input_queues = tf.train.slice_input_producer([X, Y])\n",
    "            \n",
    "    # create batch queues\n",
    "    x, y = tf.train.shuffle_batch(input_queues,\n",
    "                                num_threads=8,\n",
    "                                batch_size=hp.batch_size, \n",
    "                                capacity=hp.batch_size*64,   \n",
    "                                min_after_dequeue=hp.batch_size*32, \n",
    "                                allow_smaller_final_batch=False)\n",
    "    \n",
    "    return x, y, num_batch # (N, T), (N, T), ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define computational graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "class Graph():\n",
    "    def __init__(self, is_training=True):\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "            if is_training:\n",
    "                self.x, self.y, self.num_batch = get_batch_data() # (N, T)\n",
    "            else: # inference\n",
    "                self.x = tf.placeholder(tf.int32, shape=(None, hp.maxlen))\n",
    "                self.y = tf.placeholder(tf.int32, shape=(None, hp.maxlen))\n",
    "\n",
    "            # define decoder inputs\n",
    "            self.decoder_inputs = tf.concat((tf.ones_like(self.y[:, :1])*2, self.y[:, :-1]), -1) # 2:<S>\n",
    "\n",
    "            # Load vocabulary    \n",
    "            de2idx, idx2de = load_ja_vocab()\n",
    "            en2idx, idx2en = load_en_vocab()\n",
    "            \n",
    "            # Encoder\n",
    "            with tf.variable_scope(\"encoder\"):\n",
    "                ## Embedding\n",
    "                self.enc = embedding(self.x, \n",
    "                                      vocab_size=len(de2idx), \n",
    "                                      num_units=hp.hidden_units, \n",
    "                                      scale=True,\n",
    "                                      scope=\"enc_embed\")\n",
    "                \n",
    "                ## Positional Encoding\n",
    "                if hp.sinusoid:\n",
    "                    self.enc += positional_encoding(self.x,\n",
    "                                      num_units=hp.hidden_units, \n",
    "                                      zero_pad=False, \n",
    "                                      scale=False,\n",
    "                                      scope=\"enc_pe\")\n",
    "                else:\n",
    "                    self.enc += embedding(tf.tile(tf.expand_dims(tf.range(tf.shape(self.x)[1]), 0), [tf.shape(self.x)[0], 1]),\n",
    "                                      vocab_size=hp.maxlen, \n",
    "                                      num_units=hp.hidden_units, \n",
    "                                      zero_pad=False, \n",
    "                                      scale=False,\n",
    "                                      scope=\"enc_pe\")\n",
    "                    \n",
    "                 \n",
    "                ## Dropout\n",
    "                self.enc = tf.layers.dropout(self.enc, \n",
    "                                            rate=hp.dropout_rate, \n",
    "                                            training=tf.convert_to_tensor(is_training))\n",
    "                \n",
    "                ## Blocks\n",
    "                for i in range(hp.num_blocks):\n",
    "                    with tf.variable_scope(\"num_blocks_{}\".format(i)):\n",
    "                        ### Multihead Attention\n",
    "                        self.enc = multihead_attention(queries=self.enc, \n",
    "                                                        keys=self.enc, \n",
    "                                                        num_units=hp.hidden_units, \n",
    "                                                        num_heads=hp.num_heads, \n",
    "                                                        dropout_rate=hp.dropout_rate,\n",
    "                                                        is_training=is_training,\n",
    "                                                        causality=False)\n",
    "                        \n",
    "                        ### Feed Forward\n",
    "                        self.enc = feedforward(self.enc, num_units=[4*hp.hidden_units, hp.hidden_units])\n",
    "            \n",
    "            # Decoder\n",
    "            with tf.variable_scope(\"decoder\"):\n",
    "                ## Embedding\n",
    "                self.dec = embedding(self.decoder_inputs, \n",
    "                                      vocab_size=len(en2idx), \n",
    "                                      num_units=hp.hidden_units,\n",
    "                                      scale=True, \n",
    "                                      scope=\"dec_embed\")\n",
    "                \n",
    "                ## Positional Encoding\n",
    "                if hp.sinusoid:\n",
    "                    self.dec += positional_encoding(self.decoder_inputs,\n",
    "                                      vocab_size=hp.maxlen, \n",
    "                                      num_units=hp.hidden_units, \n",
    "                                      zero_pad=False, \n",
    "                                      scale=False,\n",
    "                                      scope=\"dec_pe\")\n",
    "                else:\n",
    "                    self.dec += embedding(tf.tile(tf.expand_dims(tf.range(tf.shape(self.decoder_inputs)[1]), 0), [tf.shape(self.decoder_inputs)[0], 1]),\n",
    "                                      vocab_size=hp.maxlen, \n",
    "                                      num_units=hp.hidden_units, \n",
    "                                      zero_pad=False, \n",
    "                                      scale=False,\n",
    "                                      scope=\"dec_pe\")\n",
    "                \n",
    "                ## Dropout\n",
    "                self.dec = tf.layers.dropout(self.dec, \n",
    "                                            rate=hp.dropout_rate, \n",
    "                                            training=tf.convert_to_tensor(is_training))\n",
    "                \n",
    "                ## Blocks\n",
    "                for i in range(hp.num_blocks):\n",
    "                    with tf.variable_scope(\"num_blocks_{}\".format(i)):\n",
    "                        ## Multihead Attention ( self-attention)\n",
    "                        self.dec = multihead_attention(queries=self.dec, \n",
    "                                                        keys=self.dec, \n",
    "                                                        num_units=hp.hidden_units, \n",
    "                                                        num_heads=hp.num_heads, \n",
    "                                                        dropout_rate=hp.dropout_rate,\n",
    "                                                        is_training=is_training,\n",
    "                                                        causality=True, \n",
    "                                                        scope=\"self_attention\")\n",
    "                        \n",
    "                        ## Multihead Attention ( vanilla attention)\n",
    "                        self.dec = multihead_attention(queries=self.dec, \n",
    "                                                        keys=self.enc, \n",
    "                                                        num_units=hp.hidden_units, \n",
    "                                                        num_heads=hp.num_heads,\n",
    "                                                        dropout_rate=hp.dropout_rate,\n",
    "                                                        is_training=is_training, \n",
    "                                                        causality=False,\n",
    "                                                        scope=\"vanilla_attention\")\n",
    "                        \n",
    "                        ## Feed Forward\n",
    "                        self.dec = feedforward(self.dec, num_units=[4*hp.hidden_units, hp.hidden_units])\n",
    "                \n",
    "            # Final linear projection\n",
    "            self.logits = tf.layers.dense(self.dec, len(en2idx))\n",
    "            self.preds = tf.to_int32(tf.arg_max(self.logits, dimension=-1))\n",
    "            self.istarget = tf.to_float(tf.not_equal(self.y, 0))\n",
    "            self.acc = tf.reduce_sum(tf.to_float(tf.equal(self.preds, self.y))*self.istarget)/ (tf.reduce_sum(self.istarget))\n",
    "            tf.summary.scalar('acc', self.acc)\n",
    "                \n",
    "            if is_training:  \n",
    "                # Loss\n",
    "                self.y_smoothed = label_smoothing(tf.one_hot(self.y, depth=len(en2idx)))\n",
    "                self.loss = tf.nn.softmax_cross_entropy_with_logits(logits=self.logits, labels=self.y_smoothed)\n",
    "                self.mean_loss = tf.reduce_sum(self.loss*self.istarget) / (tf.reduce_sum(self.istarget))\n",
    "               \n",
    "                # Training Scheme\n",
    "                self.global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "                self.optimizer = tf.train.AdamOptimizer(learning_rate=hp.lr, beta1=0.9, beta2=0.98, epsilon=1e-8)\n",
    "                self.train_op = self.optimizer.minimize(self.mean_loss, global_step=self.global_step)\n",
    "                   \n",
    "                # Summary \n",
    "                tf.summary.scalar('mean_loss', self.mean_loss)\n",
    "                self.merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load vocabulary    \n",
    "# ja2idx, idx2ja = load_ja_vocab()\n",
    "# en2idx, idx2en = load_en_vocab()\n",
    "# \n",
    "# for key in list(ja2idx.keys())[0:5]:\n",
    "#     print(key, ja2idx[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-20-ba247b957685>:123: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "Graph loaded\n",
      "INFO:tensorflow:Starting standard services.\n",
      "INFO:tensorflow:Starting queue runners.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                         | 0/1283 [00:00<?, ?b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:Recording summary at step 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▊                             | 36/1283 [01:57<1:08:04,  3.28s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.310886\n",
      "INFO:tensorflow:Recording summary at step 36.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█▊                            | 75/1283 [03:59<1:04:24,  3.20s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.324975\n",
      "INFO:tensorflow:Recording summary at step 75.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██▌                          | 113/1283 [06:00<1:02:12,  3.19s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.316655\n",
      "INFO:tensorflow:Recording summary at step 113.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|███▍                         | 150/1283 [07:57<1:00:10,  3.19s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.308369\n",
      "INFO:tensorflow:Recording summary at step 150.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████▌                          | 189/1283 [09:59<57:47,  3.17s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.325\n",
      "INFO:tensorflow:Recording summary at step 189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████▌                         | 228/1283 [11:59<55:28,  3.15s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.325\n",
      "INFO:tensorflow:Recording summary at step 228.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████▍                        | 268/1283 [13:58<52:56,  3.13s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.333334\n",
      "INFO:tensorflow:Recording summary at step 268.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|███████▍                       | 307/1283 [15:57<50:43,  3.12s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.324988\n",
      "INFO:tensorflow:Recording summary at step 307.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████▎                      | 346/1283 [17:59<48:44,  3.12s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.325012\n",
      "INFO:tensorflow:Recording summary at step 346.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████▎                     | 384/1283 [20:00<46:50,  3.13s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 384.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|██████████▏                    | 423/1283 [22:00<44:44,  3.12s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 423.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████▏                   | 461/1283 [23:58<42:45,  3.12s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 461.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████                   | 500/1283 [25:57<40:39,  3.12s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 500.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|█████████████                  | 539/1283 [27:58<38:36,  3.11s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 539.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████▉                 | 577/1283 [29:58<36:40,  3.12s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 577.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|██████████████▉                | 616/1283 [31:58<34:37,  3.11s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 616.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|███████████████▊               | 655/1283 [33:58<32:34,  3.11s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 655.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|████████████████▊              | 694/1283 [35:58<30:31,  3.11s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████████████████▍             | 721/1283 [37:22<29:07,  3.11s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 721.\n",
      "INFO:tensorflow:Recording summary at step 721.\n",
      "INFO:tensorflow:Recording summary at step 721.\n",
      "INFO:tensorflow:Recording summary at step 721.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|██████████████████▏            | 753/1283 [46:00<32:23,  3.67s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 753.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|███████████████████            | 791/1283 [47:58<29:50,  3.64s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 791.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████           | 831/1283 [49:59<27:11,  3.61s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 831.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|█████████████████████          | 870/1283 [51:57<24:39,  3.58s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 870.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|█████████████████████▉         | 910/1283 [53:59<22:07,  3.56s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 910.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|██████████████████████▉        | 949/1283 [55:57<19:41,  3.54s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 949.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████████████████████▉       | 989/1283 [57:59<17:14,  3.52s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 989.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████      | 1028/1283 [59:58<14:52,  3.50s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 1028.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|███████████████████████▎    | 1067/1283 [1:02:00<12:33,  3.49s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 1067.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████▏   | 1106/1283 [1:03:59<10:14,  3.47s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 1106.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|█████████████████████████   | 1146/1283 [1:06:00<07:53,  3.46s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 1146.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████████████████████▊  | 1185/1283 [1:07:58<05:37,  3.44s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 1185.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|██████████████████████████▋ | 1222/1283 [1:09:59<03:29,  3.44s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 1222.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|███████████████████████████▌| 1261/1283 [1:11:59<01:15,  3.43s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 1261.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                             | 15/1283 [00:46<1:05:26,  3.10s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 1298.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▎                            | 54/1283 [02:45<1:02:51,  3.07s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 1337.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▏                           | 94/1283 [04:47<1:00:34,  3.06s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 1377.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██▌                            | 108/1283 [05:30<59:53,  3.06s/b]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-22c4525ad610>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Construct graph\n",
    "g = Graph(\"train\"); print(\"Graph loaded\")\n",
    "\n",
    "# Start session\n",
    "sv = tf.train.Supervisor(graph=g.graph, \n",
    "                         logdir=hp.logdir,\n",
    "                         save_model_secs=0)\n",
    "\n",
    "with sv.managed_session() as sess:\n",
    "    for epoch in range(1, hp.num_epochs+1): \n",
    "        if sv.should_stop(): break\n",
    "        for step in tqdm.tqdm(range(g.num_batch), total=g.num_batch, ncols=70, leave=False, unit='b'):\n",
    "            sess.run(g.train_op)\n",
    "\n",
    "        gs = sess.run(g.global_step)   \n",
    "        sv.saver.save(sess, hp.logdir + '/model_epoch_%02d_gs_%d' % (epoch, gs))\n",
    "\n",
    "print(\"Done\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalute the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def eval(): \n",
    "    # Load graph\n",
    "    g = Graph(is_training=False)\n",
    "    print(\"Graph loaded\")\n",
    "    \n",
    "    # Load data\n",
    "    X, Sources, Targets = load_test_data()\n",
    "    ja2idx, idx2ja = load_ja_vocab()\n",
    "    en2idx, idx2en = load_en_vocab()\n",
    "          \n",
    "    # Start session         \n",
    "    with g.graph.as_default():    \n",
    "        sv = tf.train.Supervisor()\n",
    "        with sv.managed_session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "            ## Restore parameters\n",
    "            sv.saver.restore(sess, tf.train.latest_checkpoint(hp.logdir))\n",
    "            print(\"Restored!\")\n",
    "              \n",
    "            ## Get model name\n",
    "            mname = open(hp.logdir + '/checkpoint', 'r').read().split('\"')[1] # model name\n",
    "             \n",
    "            ## Inference\n",
    "            if not os.path.exists('results-jp-en'): os.mkdir('results-jp-en')\n",
    "            with codecs.open(\"results-jp-en/\" + mname, \"w\", \"utf-8\") as fout:\n",
    "                list_of_refs, hypotheses = [], []\n",
    "                for i in range(len(X) // hp.batch_size):\n",
    "                     \n",
    "                    ### Get mini-batches\n",
    "                    x = X[i*hp.batch_size: (i+1)*hp.batch_size]\n",
    "                    sources = Sources[i*hp.batch_size: (i+1)*hp.batch_size]\n",
    "                    targets = Targets[i*hp.batch_size: (i+1)*hp.batch_size]\n",
    "                     \n",
    "                    ### Autoregressive inference\n",
    "                    preds = np.zeros((hp.batch_size, hp.maxlen), np.int32)\n",
    "                    for j in range(hp.maxlen):\n",
    "                        _preds = sess.run(g.preds, {g.x: x, g.y: preds})\n",
    "                        preds[:, j] = _preds[:, j]\n",
    "                     \n",
    "                    ### Write to file\n",
    "                    for source, target, pred in zip(sources, targets, preds): # sentence-wise\n",
    "                        got = \" \".join(idx2en[idx] for idx in pred).split(\"</S>\")[0].strip()\n",
    "                        fout.write(\"- source: \" + source +\"\\n\")\n",
    "                        fout.write(\"- expected: \" + target + \"\\n\")\n",
    "                        fout.write(\"- got: \" + got + \"\\n\\n\")\n",
    "                        fout.flush()\n",
    "                          \n",
    "                        # bleu score\n",
    "                        ref = target.split()\n",
    "                        hypothesis = got.split()\n",
    "                        if len(ref) > 3 and len(hypothesis) > 3:\n",
    "                            list_of_refs.append([ref])\n",
    "                            hypotheses.append(hypothesis)\n",
    "                            \n",
    "                ## Calculate bleu score\n",
    "                score = corpus_bleu(list_of_refs, hypotheses)\n",
    "                fout.write(\"Bleu Score = \" + str(100*score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph loaded\n",
      "INFO:tensorflow:Starting standard services.\n",
      "WARNING:tensorflow:Standard services need a 'logdir' passed to the SessionManager\n",
      "INFO:tensorflow:Starting queue runners.\n",
      "INFO:tensorflow:Restoring parameters from logdir-jp-en/model_epoch_01_gs_1283\n",
      "Restored!\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "eval()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
